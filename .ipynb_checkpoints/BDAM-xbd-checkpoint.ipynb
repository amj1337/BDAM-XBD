{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaa3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import json\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix,graycoprops\n",
    "from skimage.measure import regionprops\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e823a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the xBD dataset images\n",
    "def load_images(image_path,image_filenames):\n",
    "    images = []\n",
    "    for filename in image_filenames:\n",
    "        image = cv2.imread(image_path + filename)  # Load image using OpenCV\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b625021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corresponding GeoJSON files and extract the building polygons\n",
    "def load_gis_data(geojson_path):\n",
    "        geojson_filenames = os.listdir(geojson_path)  # Load GeoJSON filenames\n",
    "    polygons = []\n",
    "    for filename in geojson_filenames:\n",
    "        with open(geojson_path + filename) as file:\n",
    "            data = json.load(file)\n",
    "            features = data['features']['lng_lat']  # Access the 'lng_lat' array\n",
    "            for feature in features:\n",
    "                if 'wkt' in feature:\n",
    "                    wkt_string = feature['wkt']\n",
    "                    polygon = wkt.loads(wkt_string)\n",
    "                    polygons.append(polygon)\n",
    "    gis_data = gpd.GeoDataFrame(geometry=polygons)\n",
    "    #print(gis_data)\n",
    "    return gis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ef7dd4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convert the image to 8-bit unsigned integer format\n",
    "    normalized_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "    # Resize the image to a desired size\n",
    "    resized_image = cv2.resize(normalized_image, (256, 256))\n",
    "\n",
    "    # Apply Gaussian smoothing to reduce noise\n",
    "    smoothed_image = cv2.GaussianBlur(resized_image, (5, 5), 0)\n",
    "\n",
    "    return smoothed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2f667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texture_features(image):\n",
    "    # Extract Local Binary Patterns (LBP) texture features\n",
    "    lbp_image = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 10), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add3e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shape_features(image):\n",
    "    # Check if the image is already single-channel (grayscale)\n",
    "    if len(image.shape) == 2 or (len(image.shape) == 3 and image.shape[2] == 1):\n",
    "        gray_image = image\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convert the image to 8-bit unsigned integer format\n",
    "    binary_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Extract the number of contours or other shape-related features of interest\n",
    "    shape_features = len(contours)\n",
    "\n",
    "    return shape_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90aad154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(image):\n",
    "    # Convert the image to the BGR format if it's not already\n",
    "    if len(image.shape) < 3 or image.shape[2] < 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    elif image.shape[2] > 3:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Extract color histogram features\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc83fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_overlaps_with_damaged_area(image_filename, gis_data):\n",
    "    # Load the corresponding GeoJSON file for the image\n",
    "    geojson_filename = image_filename.replace('.png', '.json')\n",
    "    geojson_filepath = os.path.join(geojson_path, geojson_filename)\n",
    "    \n",
    "    # Read the GeoJSON file and extract the polygons\n",
    "    with open(geojson_filepath) as file:\n",
    "        data = json.load(file)\n",
    "        features = data['features']\n",
    "        \n",
    "        for feature in features:\n",
    "            if 'geometry' in feature and 'coordinates' in feature['geometry']:\n",
    "                geometry = feature['geometry']\n",
    "                \n",
    "                if geometry and geometry['type'] == 'Polygon':\n",
    "                    coordinates = geometry['coordinates'][0]\n",
    "                    polygon = Polygon(coordinates)\n",
    "                    \n",
    "                    # Check if the image overlaps with the polygon\n",
    "                    if polygon.intersects(gis_data.geometry):\n",
    "                        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ceb2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the xBD dataset images and corresponding GeoJSON files\n",
    "image_path = 'train/images/'\n",
    "geojson_path = 'train/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a610d9f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_filenames = os.listdir(image_path)\n",
    "images = load_images(image_path,image_filenames)\n",
    "gis_data = load_gis_data(geojson_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c489f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of image paths in 'image_paths' variable\n",
    "\n",
    "features = []\n",
    "\n",
    "for filename in image_filenames:\n",
    "    image = cv2.imread(image_path + filename)\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "\n",
    "    texture_features = extract_texture_features(preprocessed_image)\n",
    "    shape_features = extract_shape_features(preprocessed_image)\n",
    "    color_features = extract_color_features(preprocessed_image)\n",
    "\n",
    "    # Convert shape_features to a one-dimensional array\n",
    "    shape_features = np.array([shape_features])\n",
    "\n",
    "    # Combine all the features into a single feature vector\n",
    "    feature_vector = np.concatenate((texture_features, shape_features, color_features))\n",
    "\n",
    "    features.append(feature_vector)\n",
    "\n",
    "# Now 'features' list contains the extracted features for all the images in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4367031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The Creator\\anaconda3\\envs\\proj2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\The Creator\\anaconda3\\envs\\proj2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\The Creator\\anaconda3\\envs\\proj2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training data\n",
    "labels = []  # List to store the labels for damaged areas\n",
    "# Assign labels based on overlap between images and polygons\n",
    "for image_filename in image_filenames:\n",
    "    # Check if the image overlaps with any polygons\n",
    "    # Assign a label based on the overlap\n",
    "    if image_overlaps_with_damaged_area(image_filename, gis_data):\n",
    "        labels.append(1)  # Damaged area\n",
    "    else:\n",
    "        labels.append(0)  # Not damaged area\n",
    "\n",
    "# Convert the features and labels to NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose and initialize the machine learning algorithm\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcfc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a29c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
